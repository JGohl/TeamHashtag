{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Questions\n",
    "1. Of the three million tweets, what is the breakdown by category, intent, language and time frame?\n",
    "2. Is there a relationship betewen account activity based on twitter bot category and time frame?\n",
    "3. What was the most used hashtags in the content of the tweets?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import\n",
    "On top of csv, pandas, numpy, and matplotlib, we used additional libraries for manipulating and anaylizing our data.\n",
    "\n",
    "- datetime - to change dates contained as string to a date format that can be used for boolean comparisons\n",
    "- import glob - to pull data from all csv files in the work folder\n",
    "- from progressbar import ProgressBar - to track progress of loops that took a long time to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection and build\n",
    "1. The data we used was contained in 13 separate csv files obtained from the FiveThirtyEight github. Each file was approximately 90MB. The first challenge was looping through each csv and adding it to a master data frame.\n",
    "2. Once the content was added to the master data frame, selected the columns in which we were interested. \n",
    "3. Steps one and two took considerable time given the size of the files. In order to speed this up, I combined both steps into the initial loop. A progress bar was added to the loop so we could track the progress of this loop.\n",
    "4. In loop, converted dates stored as string into datetime format using the datetime library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorize tweet date into time frame category\n",
    "1. We wanted to look at whether there was any trend in tweets during certain time frames. We defined those time frames as pre-analysis, pre-election, election-season, post-election, and post-analysis. We were interested in tweets that took place during pre-election, election-season, and post-election.\n",
    "2. Created a new columns and assigned a value based on our defined time frames.\n",
    "3. Did a time frame values count to get an idea of the total number of tweets in each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language count and graph\n",
    "1. Set the parameters for a pie graph to display the breakdown of the most used languages in the tweets.\n",
    "2. Graphed and formatted the results for the top 4 languages used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Account type and graph\n",
    "1. Set the parameters for a pie graph to display the breakdown of twitter account types.\n",
    "2. Graphed and formatted the results for the top 7 account types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Account type and graph\n",
    "1. Set the parameters for a pie graph to display the breakdown of twitter account categories, more appropriately renamed account intent.\n",
    "2. Graphed and formatted the results for the top 7 account intents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets in the analysis period\n",
    "1. Narrowed down the data frame to only tweets within the analysis period.\n",
    "2. Graphed and formatted the tweets over time, adding vertical lines to emphasize the separate of our definted time frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet content analysis\n",
    "1. To analyze the content of the tweets, I wanted to only look at tweets in English. I created a new data frame containing only English language.\n",
    "2. Split the contents of the tweets using spaces between words, and got a word count. This took quite a while to run, and returned counts of words that were not particularly useful (mostly common words like 'to', 'the', etc).\n",
    "3. Broke this down futher by finding a count of hashtags, or words that started with '#'.\n",
    "4. Turned the hashtag list and count into a data frame.\n",
    "5. Graphed top 10 hashtag tweets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
